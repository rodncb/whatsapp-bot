// M√≥dulo para transcri√ß√£o de √°udios do WhatsApp usando OpenAI Whisper
// Ativado automaticamente quando OPENAI_API_KEY estiver no .env

const axios = require("axios");
const fs = require("fs");
const path = require("path");
const FormData = require("form-data");
require("dotenv").config();

/**
 * Verifica se o suporte a √°udio est√° habilitado
 * @returns {boolean}
 */
function isAudioEnabled() {
  return !!process.env.OPENAI_API_KEY;
}

/**
 * Transcreve √°udio usando OpenAI Whisper API
 *
 * Custo: ~$0.006 por minuto de √°udio
 *
 * @param {string} audioPath - Caminho do arquivo de √°udio
 * @returns {Promise<string>} Texto transcrito
 */
async function transcribeAudio(audioPath) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error("OPENAI_API_KEY n√£o configurada no .env");
    }

    console.log(`üé§ Transcrevendo √°udio: ${path.basename(audioPath)}`);

    const formData = new FormData();
    formData.append("file", fs.createReadStream(audioPath));
    formData.append("model", "whisper-1");
    formData.append("language", "pt"); // Portugu√™s do Brasil
    formData.append("response_format", "json");

    const response = await axios.post(
      "https://api.openai.com/v1/audio/transcriptions",
      formData,
      {
        headers: {
          ...formData.getHeaders(),
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        },
        timeout: 30000, // 30 segundos
      }
    );

    const transcription = response.data.text.trim();
    console.log(`‚úÖ √Åudio transcrito: "${transcription.substring(0, 100)}..."`);

    return transcription;
  } catch (error) {
    console.error("‚ùå Erro ao transcrever √°udio:", error.message);

    if (error.response) {
      console.error("Status:", error.response.status);
      console.error("Dados:", error.response.data);
    }

    throw error;
  }
}

/**
 * Processa √°udio do WhatsApp e retorna transcri√ß√£o
 *
 * @param {Message} msg - Mensagem do WhatsApp
 * @returns {Promise<string>} Texto transcrito
 */
async function processWhatsAppAudio(msg) {
  let tempPath = null;

  try {
    console.log("üé§ Processando √°udio do WhatsApp...");

    // 1. Baixa o √°udio do WhatsApp
    const media = await msg.downloadMedia();

    if (!media) {
      throw new Error("N√£o foi poss√≠vel baixar o √°udio");
    }

    // 2. Salva temporariamente
    // Cria pasta temp se n√£o existir
    const tempDir = path.join(process.cwd(), "temp");
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    tempPath = path.join(tempDir, `audio_${Date.now()}.ogg`);
    fs.writeFileSync(tempPath, media.data, { encoding: "base64" });

    console.log(`üìÅ √Åudio salvo temporariamente: ${tempPath}`);

    // 3. Transcreve usando OpenAI Whisper
    const transcription = await transcribeAudio(tempPath);

    // 4. Remove arquivo tempor√°rio
    if (fs.existsSync(tempPath)) {
      fs.unlinkSync(tempPath);
      console.log("üóëÔ∏è  Arquivo tempor√°rio removido");
    }

    return transcription;
  } catch (error) {
    console.error("‚ùå Erro ao processar √°udio WhatsApp:", error.message);

    // Garante que remove arquivo temp mesmo em caso de erro
    if (tempPath && fs.existsSync(tempPath)) {
      try {
        fs.unlinkSync(tempPath);
      } catch (cleanupError) {
        console.error("‚ö†Ô∏è  Erro ao limpar arquivo temp:", cleanupError.message);
      }
    }

    throw error;
  }
}

module.exports = {
  isAudioEnabled,
  transcribeAudio,
  processWhatsAppAudio,
};

// ============================================
// COMO USAR NO BOT.JS:
// ============================================
/*

const audioHandler = require('./audio-handler');

client.on('message', async (msg) => {
  // ... c√≥digo existente ...

  // Se for √°udio
  if (msg.type === 'ptt' || msg.type === 'audio') {
    console.log('üé§ √Åudio recebido, transcrevendo...');
    
    try {
      // Transcreve o √°udio
      const transcription = await audioHandler.processWhatsAppAudio(msg);
      
      // Processa como se fosse texto normal
      const response = await messageHandler.handleMessage(chatId, transcription);
      await msg.reply(response.reply);
      
      if (response.shouldNotifyOwner) {
        await notifyAna(response.reason, response.contactInfo, chatId);
      }
      
    } catch (error) {
      await msg.reply('Desculpe, n√£o consegui entender seu √°udio. Pode digitar sua mensagem? üòä');
    }
    
    return;
  }

  // ... resto do c√≥digo ...
});

*/

// ============================================
// ADICIONAR NO .env:
// ============================================
/*

# OpenAI API Key (para transcri√ß√£o de √°udios)
OPENAI_API_KEY=sua_openai_api_key_aqui

*/

// ============================================
// ADICIONAR NO package.json:
// ============================================
/*

"dependencies": {
  ...
  "form-data": "^4.0.0"
}

*/
